<!DOCTYPE html>
<html lang="en">

<head>
  <title>Suraj Kothawade</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Suraj Kothawade">

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta name="description" content="Suraj Kothawade's Academic Webpage" />
  <meta name="keywords" content="computer vision, machine learning, deep learning, student, researcher" />

  <link rel="shortcut icon" href="favicon.ico">

  <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

  <!--CSS styles-->
  <link rel="stylesheet" href="Stylesheets/bootstrap.css">
  <link rel="stylesheet" href="Stylesheets/test.css">
  <link rel="stylesheet" href="Stylesheets/font-awesome.min.css">
  <link rel="stylesheet" href="Stylesheets/perfect-scrollbar-0.4.5.min.css">
  <link rel="stylesheet" href="Stylesheets/magnific-popup.css">
  <link rel="stylesheet" href="Stylesheets/style.css">
  <link id="theme-style" rel="stylesheet" href="Stylesheets/default.css">

  <link rel="stylesheet" href="Stylesheets/academicons.min.css">


  <!--/CSS styles-->
  <!--Javascript files-->
  <script type="text/javascript" src="Scripts/jquery-1.10.2.js"></script>
  <script type="text/javascript" src="Scripts/TweenMax.min.js"></script>
  <script type="text/javascript" src="Scripts/jquery.touchSwipe.min.js"></script>
  <script type="text/javascript" src="Scripts/jquery.carouFredSel-6.2.1-packed.js"></script>

  <script type="text/javascript" src="Scripts/modernizr.custom.63321.js"></script>
  <script type="text/javascript" src="Scripts/jquery.dropdownit.js"></script>

  <script type="text/javascript" src="Scripts/jquery.stellar.min.js"></script>
  <script type="text/javascript" src="Scripts/ScrollToPlugin.min.js"></script>

  <script type="text/javascript" src="Scripts/bootstrap.min.js"></script>

  <script type="text/javascript" src="Scripts/jquery.mixitup.min.js"></script>

  <script type="text/javascript" src="Scripts/masonry.min.js"></script>

  <script type="text/javascript" src="Scripts/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>

  <script type="text/javascript" src="Scripts/magnific-popup.js"></script>
  <script type="text/javascript" src="Scripts/custom.js"></script>


</head>

<body>

  <div id="wrapper">
    <a href="#sidebar" class="mobilemenu"><i class="icon-reorder"></i></a>

    <div id="sidebar">
      <div id="main-nav">
        <div id="nav-container">
          <div id="profile" class="clearfix">
            <div class="portrate hidden-xs"></div>
            <div class="title">
              <h2>Suraj Kothawade</h2>
              <h3>University of Texas at Dallas</h3>
            </div>

          </div>
          <ul id="navigation">
            <li>
              <a href="#biography">
                                <div class="icon icon-user"></div>
                                <div class="text">About Me</div>
                              </a>
            </li>

            <li>
              <a href="#research">
                                <div class="icon icon-book"></div>
                                <div class="text">Research</div>
                              </a>
            </li>

            <!-- <li>
              <a href="#selected">
                                <div class="icon icon-edit"></div>
                                <div class="text">Selected Publications</div>
                              </a>
            </li> -->
            <li>
              <a href="#publications">
                                <div class="icon icon-edit"></div>
                                <div class="text">Publications</div>
                              </a>
            </li>


            <!-- <li>
              <a href="#teaching">
                                <div class="icon icon-time"></div>
                                <div class="text">Teaching</div>
                              </a>
            </li> -->

            <!-- <li>
                              <a href="#gallery">
                                <div class="icon icon-picture"></div>
                                <div class="text">Gallery</div>
                              </a>
                            </li> -->

            <li>
              <a href="#contact">
                                  <div class="icon icon-calendar"></div>
                                  <div class="text">Contact Details</div>
                              </a>
            </li>

            <li class="external">
              <a href="surajCV.pdf" target="_blank" rel="noopener noreferrer">
                                  <div class="icon icon-download-alt"></div>
                                  <div class="text">Download CV</div>
                              </a>
            </li>
          </ul>
        </div>
      </div>

      <div class="social-icons">
        <ul>
          <li><a href="https://github.com/surajkothawade" target="_blank" rel="noopener noreferrer"><i class="icon-github"></i></a></li>
          <li><a href="https://www.linkedin.com/in/suraj-kothawade-6835b5a9/" target="_blank" rel="noopener noreferrer"><i class="icon-linkedin"></i></a></li>
          <li><a href="https://scholar.google.co.in/citations?hl=en&user=epbGOYkAAAAJ" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a></li>
        </ul>
      </div>
    </div>

    <div id="main">

      <div id="biography" class="page home" data-pos="home">
        <div class="pageheader">
          <div class="headercontent">
            <div class="section-container">

              <div class="row">
                <div class="col-sm-2 visible-sm"></div>
                <div class="col-sm-8 col-md-5">
                  <div class="biothumb">
                    <img alt="image" src="Images/suraj_iamai.jpeg"  class="img-responsive">
                    <!-- <div class="overlay">

                      <h2 class="">Suraj Kothawade</h2>
                      <ul class="list-unstyled">
                        <li>Ph.D. student in Computer Engineering</li>
                        <li>University of Texas at Dallas</li>
                      </ul>
                    </div> -->


                  </div>
                  <div>
                    <a href="https://github.com/surajkothawade" class="icon-button github" target="_blank">
                      <i class="fa fa-github icon-github" style="font-size: 44px ;" style="color:rgb(13, 0, 128);" ></i>
                      <span></span>
                    </a>
                    
                    
                    
                    <a href="https://twitter.com/surajkothawade" class="icon-button twitter" target="_blank">
                      <i class="fa fa-twitter icon-twitter"  style="font-size: 44px ;" style="color:rgb(13, 0, 128);" ></i>
                      <span></span>
                    </a>
                    
                    
                    
                    <a href="https://www.linkedin.com/in/suraj-kothawade-6835b5a9/" class="icon-button linkedin" target="_blank">
                      <i class="fa fa-linkedin icon-linkedin" style="font-size: 44px ;" style="color:rgb(13, 0, 128);" ></i>
                      <span></span>
                    </a>
                    
                    
                    
                    <a href="https://scholar.google.co.in/citations?hl=en&user=epbGOYkAAAAJ" class="icon-button gscholar" target="_blank">
                      <i class="ai ai-google-scholar icon-gscholar" style="font-size: 44px ;"  style="color:rgb(13, 0, 128);" ></i>
                      <span></span>
                    </a>
                  </div>
                </div>
                <div class="clearfix visible-sm visible-xs"></div>
                <div class="col-sm-12 col-md-7">
                  <h3 class="title">Bio</h3>
                  <p id="biodesc">I am a Senior Software Engineer at Google working on Generative Media Models with a focus on personalized image generation. Previously, I earned my Ph.D. in Computer Engineering at the University of Texas at Dallas working under the supervision of <a href="https://sites.google.com/view/rishabhiyer/">  Prof. Rishabh Iyer</a> and <a href="https://personal.utdallas.edu/~laxman/"> Prof. Lakshman Tamil</a>. My research revolves around targeted data subset selection for improving the performance of machine learning models in realistic dataset scenarios like class imbalance, redundancy and out-of-distribution data.</p>

                  <p id="biodesc">Another aspect of my research involves the use of techniques such as Active Learning and Submodular subset selection to train deep models on significantly less data, without compromising on their accuracies. I also work on visual data summarization which involves generating generic, query-focused or privacy preserving summaries of image collections or videos.</p>

                  <p id="biodesc">In Summer 2022, I worked with the <a href="https://github.com/tensorflow/models"> Tensorflow Model Garden</a> team at Google on Optimizing Vision Transformer Architechtures. In the Summer of 2020 and 2021, I worked with the Autonomous Vehicles (AV)  team at NVIDIA on improving Object Detection models deployed in AVs via Targeted Learning.</p>

                  <p id="biodesc">In my free time, I enjoy playing Badminton and <a href="https://www.runescape.com/community">Runescape</a>. I love traveling and exploring new places !</p>

                  <!-- <p id="biodesc">I am also working as a research intern at IIT Bombay under the supervision of
                  <a href="https://www.cse.iitb.ac.in/~ganesh/">  Prof. Ganesh Ramakirshnan</a>  </p> -->
                </div>

              </div>
            </div>
          </div>
        </div>

        <!-- <div class="section color-2">
          <div class="section-container">
            <div class="row">
              <div class="col-md-10 col-md-offset-1">
                <div class="title text-center">
                  <h3>News</h3>
                </div>
                <ul class="timeline">
                  <li class="open">
                    <div class="date">Sep 2021</div>
                    <div class="circle"></div>
                    <div class="data">
                      <div class="subject">1 Paper accepted to NeurIPS 2021!</div>
                    </div>
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div> -->
        
          
        <div class="pagecontents">
        
          <!-- RECENT NEWS!!!! -->
          <div class="section color-2" >
            <div class="section-container">
              <div class="row">
                <div class="col-md-20 ">
                  <div class="title text-center">
                    <h3>Recent News</h3>
                  </div style="height:auto">
                  <ul>
                    <div style="padding:3px"><li>Our paper on <a href="https://arxiv.org/abs/2407.12164"> "Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning"</a> got accepted to <b> NeurIPS 2024</b>!</li></div>
                    <div style="padding:3px"><li>Our paper on <a href="https://arxiv.org/abs/2306.01277/"> "Beyond Active Learning: Leveraging the Full Potential of Human Interaction via Auto-Labeling, Human Correction, and Human Verification"</a> got accepted to <b> WACV 2024</b>!</li></div>
                    <div style="padding:3px"><li>Our paper on <a href="https://arxiv.org/abs/2110.04908/"> "DITTO: Data-efficient and Fair Targeted Subset Selection for ASR Accent Adaptation"</a> got accepted to <b> ACL 2023 (Long Paper)</b>!</li></div>
                    <div style="padding:3px"><li>Our demo on <a href="https://csr-rki.utdallas.edu/"> "Data Exploration and Targeted Learning"</a> got accepted to <b>ECCV 2022 Demo Track!</b>!</li></div>
                    <div style="padding:3px"><li>Our paper <a href="https://arxiv.org/abs/2112.00166"> "TALISMAN: Targeted Active Learning for Object Detection with Rare Classes and Slices using Submodular Mutual Information"</a> got accepted to <b>ECCV 2022</b>!</li></div>
                     <div style="padding:3px"><li>Our paper <a href="https://arxiv.org/abs/2201.12928"> "PLATINUM: Semi-Supervised Model Agnostic Meta-Learning
                      using Submodular Mutual Information"</a> got accepted to <b>ICML 2022</b>!</li></div>
                     <div style="padding:3px"><li>Our demonstration <a href="https://arxiv.org/abs/2201.12928"> "An Efficient Data Exploration Framework for Effective Learning"</a> got accepted at the IEEE Intelligent Vehicles Symposium <b>IV 2022</b>!</li></div>
                     <div style="padding:3px"><li>I was awarded the prestigious <b>Jan Van der Ziel Fellowship</b> at UT Dallas.</li></div>
                     <div style="padding:3px"><li>My dissertation titled <b>"Data Exploration and Targeted Learning"</b> was awarded the <b>runner-up</b> at the <b>3-Minute-Thesis (3MT)</b> competition hosted by UT Dallas.</li></div>
                     <div style="padding:3px"><li>Our paper <a href="https://arxiv.org/abs/2112.00166"> "Object Level Targeted Selection using Deep Template Matching"</a> got accepted at the IEEE Intelligent Vehicles Symposium <b>IV 2022</b>!</li></div>
                     <div style="padding:3px"><li>Passed Ph.D. Proposal Exam!</li></div>
                     <div style="padding:3px"><li>Our paper <a href="https://arxiv.org/abs/2103.00128"> "PRISM: A Unified Framework of Parameterized Submodular Information Measures for Targeted Data Subset Selection and Summarization"</a> got accepted to <b>AAAI 2022</b>!</li></div>
                     <div style="padding:3px"><li>Accepted for Doctoral Consortium at <b>WACV 2022</b>.</li></div>
                     <div style="padding:3px"><li>Our paper <a href="https://arxiv.org/abs/2107.00717"> "SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios"</a> got accepted to <b>NeurIPS 2021</b>!</li></div>
                     <div style="padding:3px"><li>Three papers accepted to <b>WACV 2019</b>!</li></div>
  
                    
                </div>
              </div>
            </div>
          </div>
        
          <!-- SELECTED PUBLICATIONS!!!! -->
       
        <div  class="section color-2">
            <div class="section-container">
              <div class="row">
                <div class="col-md-20 ">
                  <div class="title text-center">
                    <h3 id="selected">Selected Publications</h3>
                  </div>
                  <a>[* Equal Contribution]</a>
                  <ul style="overflow-x: auto;
                  overflow-y: auto;">

                  <!-- TALISMAN -->
                    <li style="list-style-type: none;">
                      <div style="display: flex;
                      /* border-top: thin solid #c0c0c0; */
                      radius: 55px;
                      padding-top: -webkit-calc((10px / 2));
                      padding-top: -calc(10px / 2);
                      padding-bottom: -webkit-calc((10px / 2));
                      padding-bottom: -calc(10px / 2);
                      overflow: auto;">
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: left;float: left;
                        width: -webkit-calc(30% - (10px / 2));
                        width: calc(30% - (10px / 2));
                        text-align: center;
                        margin-right: auto;">
                          <img style="width: 400px;
                          border: 1px solid #9b3022;
                          border-radius: 3%;
                          box-shadow: 5px 5px 15px rgb(173 181 189 / 40%);max-width: 100%;
                          vertical-align: middle;" src="Images/talisman_flow.jpg"/>
                        </div>
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: center;float: right;
                        width: -webkit-calc(70% - (10px / 2));
                        width: calc(70% - (10px / 2));">
                          <div class="title">
                            <b>TALISMAN: Targeted Active Learning for Object Detection with Rare Classes and Slices using Submodular Mutual Information</b>
                          </div>
                          <div class="authors"><a class="author" href="https://www.linkedin.com/in/surajkothawade/"><strong>Suraj Kothawade</strong></a>,
                            <a class="author">Saikat Ghosh</a>,
                            <a class="author">Sumit Shekhar</a>,
                            <a class="author">Yu Xiang</a>,
                            <a class="author">Rishabh Iyer</a>
                            
                          </div>
                          <div class="publisher">
                              <span class="publisher"><b>European Conference in Computer Vision, ECCV 2022</b></span>
                              <span class="publisher_oral">&nbsp</span>
                          </div>
                          <div class="desc" >
                            <p>
                              Deep models often perform well in terms of overall accuracy, they often struggle in performance on rare yet critical data slices. For example, data slices like "motorcycle at night" or "bicycle at night" are often rare but very critical slices for self-driving applications and false negatives on such rare slices could result in ill-fated failures and accidents. TALISMAN uses the submodular mutual information functions instantiated using features of the region of interest (RoI) to efficiently target and acquire data points with rare slices. These acquired rare data points can then be used to improve the performance on the rare slices.
                            </p>
                          </div>
                          <div class="publish">
                            <!--
                            <span class="publisher">International Conference on Learning Representations (ICLR) 2020</span>
                            -->
                            <span class="status"></span>
                            <span class="place"></span>
                          </div>
                          <div class="tags">
                            
                            [<a class="tag" href="https://arxiv.org/pdf/2112.00166.pdf"> <strong>Paper</strong> </a>]
                            
                            [<a class="tag" href="https:/"> <strong>Poster</strong> </a>]
                            
                            <!-- [<a class="tag" href="https:YDH"> <strong>OpenReview</strong> </a>] -->
                            
                            [<a class="tag" href="Slides/talisman.pdf"> <strong>Slides</strong> </a>]
                            
                            [<a class="tag" href="https://scholar.googleusercontent.com/scholar.bib?q=info:mD9AcnqiiI8J:scholar.google.com/&output=citation&scisdr=CgXtKwIeEOOWq0mbATo:AAGBfm0AAAAAYsSdGTrSNlQf75WtFie4_I1tlVJqrAQ5&scisig=AAGBfm0AAAAAYsSdGUj18nDmmRo-d4TOCAysRzn8Qs7B&scisf=4&ct=citation&cd=-1&hl=en"> <strong>Bibtex</strong> </a>]
                            
                          </div>
                        </div>
                      </div>
                    </li>
                      
                    <!-- PLATINUM -->
                    <li style="list-style-type: none;">
                      <div style="display: flex;
                      border-top: thin solid #c0c0c0;
                      radius: 55px;
                      padding-top: -webkit-calc((10px / 2));
                      padding-top: -calc(10px / 2);
                      padding-bottom: -webkit-calc((10px / 2));
                      padding-bottom: -calc(10px / 2);
                      overflow: auto;">
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: left;float: left;
                        width: -webkit-calc(30% - (10px / 2));
                        width: calc(30% - (10px / 2));
                        text-align: center;
                        margin-right: auto;">
                          <img style="width: 400px;
                          border: 1px solid #9b3022;
                          border-radius: 3%;
                          box-shadow: 5px 5px 15px rgb(173 181 189 / 40%);max-width: 100%;
                          vertical-align: middle;" src="Images/platinum_flow.jpg"/>
                        </div>
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: center;float: right;
                        width: -webkit-calc(70% - (10px / 2));
                        width: calc(70% - (10px / 2));">
                          <div class="title">
                            <b>PLATINUM: Semi-Supervised Model Agnostic Meta-Learning using Submodular Mutual Information</b>
                          </div>
                          <div class="authors">
                            <a class="author">Changbin Li*</a>,
                            <a class="author" href="https://www.linkedin.com/in/surajkothawade/"><strong>Suraj Kothawade*</strong></a>,
                            <a class="author">Feng Chen</a>,
                            <a class="author">Rishabh Iyer</a>
                            
                          </div>
                          <div class="publisher">
                              <span class="publisher"><b>International Conference in Machine Learning, ICML 2022</b></span>
                              <span class="publisher_oral">&nbsp (Spotlight)</span>
                          </div>
                          <div class="desc" >
                            <p>
                              Few-shot classification (FSC) requires training models using a few (typically one to five) data points per class. Meta learning has proven to be able to learn a parametrized model for FSC by training on various other classification tasks.  PLATINUM leverages unlabeled data and embeds semi-supervision in the inner and outer loop using SMI functions during meta-training and obtains richer meta-learned parameterizations for meta-test. 
                            </p>
                          </div>
                          
                          <div class="publish">
                            <!--
                            <span class="publisher">International Conference on Learning Representations (ICLR) 2020</span>
                            -->
                            <span class="status"></span>
                            <span class="place"></span>
                          </div>
                          <div class="tags">
                            
                            [<a class="tag" href="https://arxiv.org/abs/2201.12928"> <strong>Paper</strong> </a>]
                            
                            [<a class="tag" href="Posters/platinum_poster_v1.pdf"> <strong>Poster</strong> </a>]
                                                        
                            [<a class="tag" href="Slides/platinum_talk_new.pdf"> <strong>Slides</strong> </a>]

                            [<a class="tag" href="https://slideslive.com/38983304/platinum-semisupervised-model-agnostic-metalearning-using-submodular-mutual-information#"> <strong>Talk</strong> </a>]
                            
                            [<a class="tag" href="https://scholar.googleusercontent.com/scholar.bib?q=info:jLPKSFqz2w4J:scholar.google.com/&output=citation&scisdr=CgXtKwIeEOOWq0mu7lc:AAGBfm0AAAAAYsSo9lelc_vis7N5xhbBo0fbt-mxM8hg&scisig=AAGBfm0AAAAAYsSo9ltPuaNrn5RrEcqsLLW3bxmyikmG&scisf=4&ct=citation&cd=-1&hl=en"> <strong>Bibtex</strong> </a>]
                            
                          </div>
                        </div>
                      </div>
                    </li>


                    <!-- DEEP TEMPLATE MATCHING -->
                    <li style="list-style-type: none;">
                      <div style="display: flex;
                      border-top: thin solid #c0c0c0;
                      radius: 55px;
                      padding-top: -webkit-calc((10px / 2));
                      padding-top: -calc(10px / 2);
                      padding-bottom: -webkit-calc((10px / 2));
                      padding-bottom: -calc(10px / 2);
                      overflow: auto;">
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: left;float: left;
                        width: -webkit-calc(30% - (10px / 2));
                        width: calc(30% - (10px / 2));
                        text-align: center;
                        margin-right: auto;">
                          <img style="width: 400px;
                          border: 1px solid #9b3022;
                          border-radius: 3%;
                          box-shadow: 5px 5px 15px rgb(173 181 189 / 40%);max-width: 100%;
                          vertical-align: middle;" src="Images/dtm_flow.jpg"/>
                        </div>
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: center;float: right;
                        width: -webkit-calc(70% - (10px / 2));
                        width: calc(70% - (10px / 2));">
                          <div class="title">
                            <b>Object-Level Targeted Selection via Deep Template Matching</b>
                          </div>
                          <div class="authors">
                            <a class="author" href="https://www.linkedin.com/in/surajkothawade/"><strong>Suraj Kothawade</strong></a>,
                            <a class="author">Donna Roy</a>,
                            <a class="author">Michele Fenzi</a>,
                            <a class="author">Elmar Haussmann</a>,
                            <a class="author">Jose M. Alvarez</a>,
                            <a class="author">Christoph Angerer</a>
                            
                          </div>
                          <div class="publisher">
                              <span class="publisher"><b>Intelligent Vehicles Symposium, IV 2022</b></span><br>
                              <span class="publisher"><b>Machine Learning for Autonomous Driving Workshop, NeurIPS 2021</b></span>
                              <span class="publisher_oral">&nbsp (Spotlight)</span>
                          </div>
                          <div class="desc" >
                            <p>
                              The targeted selection task requires finding the relevant data from a large-scale pool of unlabeled data. Manual mining at this scale is infeasible. Further, the OOI are often small and occupy less than 1% of image area are occluded, and co-exist with many semantically different objects in cluttered scenes. We propose a fast and robust template matching algorithm in the DNN feature space, that retrieves semantically similar images at the object-level from a large unlabeled pool of data. The mining is done using patchwise similarity which can efficiently mine objects that are small, occluded and amidst clutter.
                            </p>
                          </div>
                          
                          <div class="publish">
                            <span class="status"></span>
                            <span class="place"></span>
                          </div>
                          <div class="tags">
                            
                            [<a class="tag" href="https://arxiv.org/abs/2207.01778"> <strong>Paper</strong> </a>]
                            
                            [<a class="tag" href="Posters/nvidia_dtm_poster_iv2022.pdf"> <strong>Poster</strong> </a>]
                                                        
                            [<a class="tag" href="Slides/dtm_ml4ad.pdf"> <strong>Slides</strong> </a>]

                            [<a class="tag" href="https://slideslive.com/38971222/objectlevel-targeted-selection-via-deep-template-matching?ref=speaker-82284"> <strong>Talk</strong> </a>]
                            
                            [<a class="tag" href="/"> <strong>Bibtex</strong> </a>]
                            
                          </div>
                        </div>
                      </div>
                    </li>


                    <!-- PRISM  -->
                    <li style="list-style-type: none;">
                      <div style="display: flex;
                      border-top: thin solid #c0c0c0;
                      radius: 55px;
                      padding-top: -webkit-calc((10px / 2));
                      padding-top: -calc(10px / 2);
                      padding-bottom: -webkit-calc((10px / 2));
                      padding-bottom: -calc(10px / 2);
                      overflow: auto;">
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: left;float: left;
                        width: -webkit-calc(30% - (10px / 2));
                        width: calc(30% - (10px / 2));
                        text-align: center;
                        margin-right: auto;">
                          <img style="width: 400px;
                          border: 1px solid #9b3022;
                          border-radius: 3%;
                          box-shadow: 5px 5px 15px rgb(173 181 189 / 40%);max-width: 100%;
                          vertical-align: middle;" src="Images/prism_flow.jpg"/>
                        </div>
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: center;float: right;
                        width: -webkit-calc(70% - (10px / 2));
                        width: calc(70% - (10px / 2));">
                          <div class="title">
                            <b>PRISM: A Rich Class of Parameterized Submodular Information Measures for Guided Subset Selection</b>
                          </div>
                          <div class="authors">
                            <a class="author" href="https://www.linkedin.com/in/surajkothawade/"><strong>Suraj Kothawade</strong></a>,
                            <a class="author">Vishal Kaushal</a>,
                            <a class="author">Ganesh Ramakrishnan</a>,
                            <a class="author">Jeff Bilmes</a>,
                            <a class="author">Rishabh Iyer</a>
                            
                          </div>
                          <div class="publisher">
                              <span class="publisher"><b>AAAI Conference on Artificial Intelligence, AAAI 2022</b></span><br>
                              <span class="publisher"><b>ICLR 2021 Workshop: From Shallow to Deep: Overcoming Limited and Adverse Data</b></span>
                              <span class="publisher_oral">&nbsp </span>
                          </div>
                          <div class="desc" >
                            <p>
                              Through novel functions and their parameterizations, PRISM offers a variety of modeling capabilities that enable a trade-off between desired qualities of a subset like diversity or representation and similarity/dissimilarity with a set of data points. We demonstrate how PRISM can be applied to Guided Subset Selection tasks like Targeted learning and Guided Summarization.
                            </p>
                          </div>
                          
                          <div class="publish">
                            <span class="status"></span>
                            <span class="place"></span>
                          </div>
                          <div class="tags">
                            
                            [<a class="tag" href="https://arxiv.org/abs/2103.00128"> <strong>Paper</strong> </a>]
                            
                            [<a class="tag" href="Posters/prism_poster.pdf"> <strong>Poster</strong> </a>]
                                                        
                            [<a class="tag" href="Slides/prism_talk.pdf"> <strong>Slides</strong> </a>]
                            
                            [<a class="tag" href="https://slideslive.com/38955382/submodular-mutual-information-for-targeted-data-subset-selection?ref=folder-83389"> <strong>Talk</strong> </a>] 
                            
                            [<a class="tag" href="https://github.com/decile-team/trust"> <strong>Code</strong> </a>] 
                            
                            [<a class="tag" href="https://scholar.googleusercontent.com/scholar.bib?q=info:G_iDrFL-AgcJ:scholar.google.com/&output=citation&scisdr=CgXtKwIeEOOWq0m0aLg:AAGBfm0AAAAAYsSycLgPHetYp0lY9KNLCAbv-723IKfI&scisig=AAGBfm0AAAAAYsSycAaWD0Z4-onQGS5-r0Q_QFNX8fi7&scisf=4&ct=citation&cd=-1&hl=en"> <strong>Bibtex</strong> </a>]
                            
                          </div>
                        </div>
                      </div>
                    </li>

                    <!-- SIMILAR  -->
                    <li style="list-style-type: none;">
                      <div style="display: flex;
                      border-top: thin solid #c0c0c0;
                      radius: 55px;
                      padding-top: -webkit-calc((10px / 2));
                      padding-top: -calc(10px / 2);
                      padding-bottom: -webkit-calc((10px / 2));
                      padding-bottom: -calc(10px / 2);
                      overflow: auto;">
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: left;float: left;
                        width: -webkit-calc(30% - (10px / 2));
                        width: calc(30% - (10px / 2));
                        text-align: center;
                        margin-right: auto;">
                          <img style="width: 400px;
                          border: 1px solid #9b3022;
                          border-radius: 3%;
                          box-shadow: 5px 5px 15px rgb(173 181 189 / 40%);max-width: 100%;
                          vertical-align: middle;" src="Images/similar_flow.jpg"/>
                        </div>
                        <div style="display: flex;
                        flex-direction: column;
                        justify-content: center;
                        align-items: center;float: right;
                        width: -webkit-calc(70% - (10px / 2));
                        width: calc(70% - (10px / 2));">
                          <div class="title">
                            <b>SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios</b>
                          </div>
                          <div class="authors">
                            <a class="author" href="https://www.linkedin.com/in/surajkothawade/"><strong>Suraj Kothawade</strong></a>,
                            <a class="author">Nathan Beck</a>,
                            <a class="author">Krishnateja Killamsetty</a>,
                            <a class="author">Rishabh Iyer</a>
                            
                          </div>
                          <div class="publisher">
                              <span class="publisher"><b>Neural Information Processing Systems, NeurIPS 2021</b></span><br>
                              <span class="publisher"><b>ICML 2021 Workshop: Subset Selection in Machine Learning</b></span>
                              <span class="publisher_oral">&nbsp </span>
                          </div>
                          <div class="desc" >
                            <p>
                              Existing active learning methods do not work well in realistic scenarios such as imbalance or rare classes, out-of-distribution data in the unlabeled set, and redundancy. In this work, we propose SIMILAR, a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions. We argue that SIMILAR not only works in standard active learning, but also easily extends to the realistic settings considered above and acts as a one-stop solution for active learning that is scalable to large real-world datasets. 
                            </p>
                          </div>
                          
                          <div class="publish">
                            <span class="status"></span>
                            <span class="place"></span>
                          </div>
                          <div class="tags">
                            
                            [<a class="tag" href="https://arxiv.org/abs/2107.00717"> <strong>Paper</strong> </a>]
                            
                            [<a class="tag" href="Posters/similar_poster.pdf"> <strong>Poster</strong> </a>]
                                                        
                            [<a class="tag" href="Slides/similar_final_v2.pdf"> <strong>Slides</strong> </a>]
                            
                            [<a class="tag" href="https://slideslive.com/38968661/similar-submodular-information-measures-based-active-learning-in-realistic-scenarios?ref=speaker-82284"> <strong>Talk</strong> </a>]
                            
                            [<a class="tag" href="https://caraml-lab.medium.com/similar-submodular-information-measures-based-active-learning-in-realistic-scenarios-a9eb8c1d9047"> <strong>Blog</strong> </a>]

                            [<a class="tag" href="https://github.com/decile-team/distil"> <strong>Code</strong> </a>]
                            
                            [<a class="tag" href="https://scholar.googleusercontent.com/scholar.bib?q=info:mWFIk0JkWRgJ:scholar.google.com/&output=citation&scisdr=CgXtKwIeEOOWq0mw1jc:AAGBfm0AAAAAYsS2zjePkZ-NZykhGR0pj-LFkSTCvue8&scisig=AAGBfm0AAAAAYsS2zpMKAs_glCFwRbH-54dkQ60BALxq&scisf=4&ct=citation&cd=-1&hl=en"> <strong>Bibtex</strong> </a>]
                            
                          </div>
                        </div>
                      </div>
                    </li>
                  
                  </ul>
                  <a href="#publications"><b>Full Publication List</b></a> 
                </div>
              </div>
            </div>
          </div>  
          

          <!-- WORK EXPERIENCE -->
          <div class="section color-1">
            <div class="section-container">
              <div class="row">
                <div class="col-md-5 col-md-offset-1">
                  <div class="title text-center">
                    <h3>Work Experience</h3>
                  </div>
                  <ul class="ul-dates">
                    <li>
                      <div class="dates">
                        <span>Present</span>
                        <span>05/2022</span>
                      </div>
                      <div class="content">
                        <h4>Research Intern</h4>
                        <p><em>Google - Tensorflow Model Garden Team, Mountain View, CA</em></p>
                      </div>
                    </li>

                    <li>
                      <div class="dates">
                        <span>05/2022</span>
                        <span>01/2022</span>
                      </div>
                      <div class="content">
                        <h4>Research Assistant</h4>
                        <p><em>University of Texas at Dallas</em></p>
                      </div>
                    </li>

                    <li>
                      <div class="dates">
                        <span>12/2021</span>
                        <span>08/2021</span>
                      </div>
                      <div class="content">
                        <h4>Teaching Assistant</h4>
                        <p><em>University of Texas at Dallas</em></p>
                      </div>
                    </li>

                    <li>
                      <div class="dates">
                        <span>08/2021</span>
                        <span>05/2021</span>
                      </div>
                      <div class="content">
                        <h4>AI Research Intern</h4>
                        <p><em>NVIDIA Autonomous Vehicles Team, Santa Clara, CA</em></p>
                      </div>
                    </li>

                    <li>
                      <div class="dates">
                        <span>05/2021</span>
                        <span>01/2021</span>
                      </div>
                      <div class="content">
                        <h4>Teaching Assistant</h4>
                        <p><em>University of Texas at Dallas</em></p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>01/2021</span>
                        <span>05/2020</span>
                      </div>
                      <div class="content">
                        <h4>AI Research Intern</h4>
                        <p><em>NVIDIA Autonomous Vehicles Team, Santa Clara, CA</em></p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>05/2020</span>
                        <span>08/2019</span>
                      </div>
                      <div class="content">
                        <h4>Teaching Assistant</h4>
                        <p><em>University of Texas at Dallas</em></p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>08/2019</span>
                        <span>03/2019</span>
                      </div>
                      <div class="content">
                        <h4>Research Assistant</h4>
                        <p><em>Advisor: Prof. Stefanos Nikolaidis, ICAROS lab, University of Southern California</em></p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>12/2018</span>
                        <span>04/2018</span>
                      </div>
                      <div class="content">
                        <h4>Machine Learning Engineer</h4>
                        <p><em>AitoeLabs</em>, India</p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>06/2018</span>
                        <span>12/2017</span>
                      </div>
                      <div class="content">
                        <h4>Research Intern</h4>
                        <p><em>Advisor: Prof. Ganesh Ramakirshnan, Indian Institute of Technology, Bombay</em>, India</p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>07/2017</span>
                        <span>05/2017</span>
                      </div>
                      <div class="content">
                        <h4>Eklavya Research Intern</h4>
                        <p><em>Advisor: Prof. Deepak B. Phatak, Indian Institute of Technology, Bombay</em>, India</p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>01/2016</span>
                        <span>12/2015</span>
                      </div>
                      <div class="content">
                        <h4>Research Intern</h4>
                        <p><em>Tata Consultancy Services, Innovation Labs, Mumbai</em>, India</p>
                      </div>
                    </li>
                  </ul>
                </div>

                <!-- EDUCATION -->
                <div class="col-md-5">
                  
                  <div class="title text-center">
                    <h3>Achievements and Awards</h3>
                  </div>
                  <ul class="timeline">

                    <li class="open">
                      <div class="date">Apr 2022</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Jan Van der Ziel Fellowship</div>
                        <div class="text row">
                          <div class="col-md-12">
                            A prestigious merit-based fellowship awarded to one Ph.D. student at the University of Texas at Dallas.
                          </div>
                        </div>
                      </div>
                    </li>

                    <li class="open">
                      <div class="date">Apr 2022</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Runner Up at the UT Dallas Three Minute Thesis (3MT) competition</div>
                        <div class="text row">
                          <div class="col-md-12">
                            The 3MT competition was started by The University of Queensland, which encourages PhD students to present their research to a general audience in under 3 minutes using just one PowerPoint slide!
                          </div>
                        </div>
                      </div>
                    </li>

                    <li class="open">
                      <div class="date">Apr 2018</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Best Student Award</div>
                        <div class="text row">
                          <div class="col-md-12">
                            Awarded the title for being the most outstanding student by Tata Consultancy Services.
                          </div>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="date">Apr 2018</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Best Project Award</div>
                        <div class="text row">
                          <div class="col-md-12">
                            Awarded the title by Tata Consultancy Services for the work done for Indian Space Reseach Organisation (ISRO) on 'Content Based Image Retrieval from AWiFS Images Repository of IRS Resourcesat-2 Satellite Based on Water Bodies and Burnt Areas'.
                          </div>
                        </div>
                      </div>
                    </li>

                    <!-- <li>
                      <div class="date">Dec 2017</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Best Paper Award</div>
                        <div class="text row">
                          <div class="col-md-12">
                            Awarded the Best Paper at '2017 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC).'
                          </div>
                        </div>
                      </div>
                    </li> -->

                    <li>
                      <div class="date">Dec 2017</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Honorable Mention at ACM ICPC 2017</div>
                        <div class="text row">
                          <div class="col-md-12">
                            Qualified for ACM ICPC 2017 Regionals
                          </div>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="date">Aug 2017</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Departmental Gold Medalist - Junior Year</div>
                        <div class="text row">
                          <div class="col-md-12">
                            Ranked 1/160 in Computer science & Engineering department in Junior year.
                          </div>
                        </div>
                      </div>
                    </li>

                  </ul>

                </div>
              </div>
            </div>

          </div>
          
          
          <!-- ACHIEVEMENTS AND AWARDS!!!! -->
          <div class="section color-2">
            <div class="section-container">
              <div class="row">
                <div class="col-md-10 col-md-offset-1">


                  <div class="title text-center">
                    <h3>Education</h3>
                  </div>
                  <ul class="ul-card">
                    <li>
                      <div class="dy">
                        <span class="degree">Doctor of Philosophy</span>
                        <span class="year">2023</span>
                      </div>
                      <div class="description">
                        <p class="waht">Ph.D. in Computer Engineering</p>
                        <p class="where">University of Texas at Dallas</p>
                      </div>
                    </li>
                    <li>
                      <div class="dy">
                        <span class="degree">Master of Science</span>
                        <span class="year">2019</span>
                      </div>
                      <div class="description">
                        <p class="waht">MS in Computer Science</p>
                        <p class="where">University of Southern California</p>
                        <p class="where">Transferred to University of Texas at Dallas for research in optimization and data subset selection</p>
                      </div>
                    </li>
                    <li>
                      <div class="dy">
                        <span class="degree">Bachelor of Technology</span>
                        <span class="year">2018</span>
                      </div>
                      <div class="description">
                        <p class="waht">B.Tech in Computer Science and Engineering</p>
                        <p class="where">SGGS Institute of Engineering and Technology</p>
                        <p class="where">(An Autonomous Institute of Government of Maharashtra)</p>
                      </div>
                    </li>
                    <li>
                      <div class="dy">
                        <span class="degree">Senior Secondary</span><span class="year">2014</span>
                      </div>
                      <div class="description">
                        <p class="waht">All India Senior School Certificate Exam</p>
                        <p class="where">M.H High School, Thane</p>
                      </div>
                    </li>

                  </ul>


                  
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div id="research" class="page">
        <div class="pageheader">

          <div class="headercontent">

            <div class="section-container">
              <h2 class="title">Research Summary</h2>

              <div class="row">
                <div class="col-md-8">
                  <p id="biodesc">Primarily my research focus has been on using Machine Learning techniques to solve Computer Vision tasks. I am extremely interested in understanding how models can learn from less data, without suffering a
                    significant drop in accuracy. </p>
                  <p id="biodesc">Over the past few years, I have been exploring the subject of Submodular Optimization and how it can be used to solve tasks such as visual summarization and data subset selection. Coupling submodular optimization with
                    machine learning, opens possibilities to solve computer vision problems with less, but diverse and representative, data.</p>
                </div>
                <div class="col-md-4">
                  <div class="subtitle text-center">
                    <h3>Interests</h3>
                  </div>
                  <ul class="ul-boxed list-unstyled">
                    <li>Computer Vision</li>
                    <li>Deep Learning</li>
                    <li>Machine Learning</li>
                    <li>Optimization</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>

        <div class="pagecontents">
          <!-- <div class="section color-1">
                            <div class="section-container">
                                <div class="title text-center">
                                    <h3>Laboratory Personel</h3>
                                </div>
                                <div class="row">
                                    <div class="col-md-8">

                                        <div id="labp-heads-wrap">

                                            <div id="lab-carousel">
                                                <div><img alt="image" src="img/lab/lab5.jpg" width="120" height="120" class="img-circle lab-img" /></div>
                                                <div><img alt="image" src="img/lab/lab2.jpg" width="120" height="120" class="img-circle lab-img" /></div>
                                                <div><img alt="image" src="img/lab/lab1.jpg" width="120" height="120" class="img-circle lab-img" /></div>
                                                <div><img alt="image" src="img/lab/lab4.jpg" width="120" height="120" class="img-circle lab-img" /></div>
                                                <div><img alt="image" src="img/lab/lab3.jpg" width="120" height="120" class="img-circle lab-img" /></div>
                                                <div><img alt="image" src="img/lab/lab6.jpg" width="120" height="120" class="img-circle lab-img" /></div>
                                            </div>
                                            <div>
                                                <a href="#" id="prev"><i class="icon-chevron-sign-left"></i></a>
                                                <a href="#" id="next"><i class="icon-chevron-sign-right"></i></a>
                                            </div>
                                        </div>

                                        <div id="lab-details">
                                            <div>
                                                <h3>David A. Doe</h3>
                                                <h4>Postdoctoral fellow</h4>
                                                <a href="#" class="btn btn-info">+ Follow</a>
                                            </div>
                                            <div>
                                                <h3>James Doe</h3>
                                                <h4>Postdoctoral fellow</h4>
                                                <a href="#" class="btn btn-info">+ Follow</a>
                                            </div>
                                            <div>
                                                <h3>Nadja Sriram</h3>
                                                <h4>Postdoctoral fellow</h4>
                                                <a href="#" class="btn btn-info">+ Follow</a>
                                            </div>
                                            <div>
                                                <h3>Davide Doe</h3>
                                                <h4>Research Assistant</h4>
                                                <a href="#" class="btn btn-info">+ Follow</a>
                                            </div>
                                            <div>
                                                <h3>Pauline Doe</h3>
                                                <h4>Summer Intern</h4>
                                                <a href="#" class="btn btn-info">+ Follow</a>
                                            </div>
                                            <div>
                                                <h3>James Doe</h3>
                                                <h4>Postdoctoral fellow</h4>
                                                <a href="#" class="btn btn-info">+ Follow</a>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="col-md-4">
                                        <h3>Great lab Personel!</h3>
                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
                                    </div>
                                </div>
                            </div>
                        </div> -->
          <div class="section color-2">
            <div class="section-container">
              <div class="title text-center">
                <h3>Projects and Open-Source Contributions</h3>
              </div>
              <div class="row">
                <div class="col-md-12">
                  <ul class="ul-withdetails">
                    
                    <!-- #### DISTIL ### -->
                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>DISTIL: Deep dIverSifed inTeractIve Learning</h3>
                            <p>DISTIL implements a number of state-of-the-art active learning algorithms.</p>
                            <a href="https://github.com/decile-team/distil" class="tooltips" title="GitHub Link" target="_blank" rel="noopener noreferrer">
                              <i class="icon-external-link"></i>
                            </a>
                          </div>
                        </div>
                      </div>
                    </li>

                    <!-- #### TRUST ### -->
                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>TRUST: TaRgeted sUbSet selecTion</h3>
                            <p>TRUST supports a number of algorithms for targeted selection which provides a mechanism to include additional information via data to priortize the semantics of the selection.</p>
                            <a href="https://github.com/decile-team/trust" class="tooltips" title="GitHub Link" target="_blank" rel="noopener noreferrer">
                              <i class="icon-external-link"></i>
                            </a>
                          </div>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>Vis-DSS: Visual Data Selection and Summarization</h3>
                            <p>An open-source toolkit for Image and Video Summarization, Data Subset Selection and Diversified Active Learning using Submodular functions.</p>
                            <a href="https://github.com/surajkothawade/vis-dss" class="tooltips" title="GitHub Link" target="_blank" rel="noopener noreferrer">
                              <i class="icon-external-link"></i>
                            </a>
                          </div>
                        </div>
                      </div>
                    </li>
                    
                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>Jensen: Convex Optimization and ML toolkit</h3>
                            <p>A C++ toolkit with API support for Convex Optimization and Machine Learning.</p>
                            <a href="https://github.com/decile-team/jensen" class="tooltips" title="GitHub Link" target="_blank" rel="noopener noreferrer">
                              <i class="icon-external-link"></i>
                            </a>
                          </div>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>Massive scale search and recognition (Bhopal Police, Madhya Pradesh, India)</h3>
                            <p>Implementing person search, face search, face recognition and text search on thousands of hours of footage from surveillance cameras for the police department in Bhopal.</p>
                          </div>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>Compliance and Quality Monitoring System (Ministry of Rural Development)</h3>
                            <p>Led a team of four people to develop a product for the Ministry of Rural Development. The product comprised of four clasroom compliances that enabled the user to monitor the duration for which the classes were actually conducted during a day, the attendance in each class, the instructor who taught the class and the number of people wearing uniform.</p>
                          </div>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-12">
                          <div class="meta">
                            <h3>CBIR on AWiFS Data from Large Satellite Image Repository (Indian Space Research Organization)</h3>
                            <p>Worked extensively on the Analytics including Machine Learning, Feature Engineering and Code Optimization to identify Water bodies and Burnt Areas from the satellite image based on multiple algorithms. </p>
                          </div>
                        </div>
                      </div>
                    </li>

                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div id="publications" class="page">
        <div class="page-container">
          <div class="pageheader">
            <div class="headercontent">
              <div class="section-container">

                <h2 class="title">Publications</h2>
                <!-- <div class="row">
                                        <div class="col-md-12">
                                        </div>
                                    </div> -->

              </div>
            </div>
          </div>

          <div class="pagecontents">

            <!-- <div class="section color-1" id="filters">
                                <div class="section-container">
                                    <div class="row">

                                        <div class="col-md-3">
                                            <h3>Filter by type:</h3>
                                        </div>
                                        <div class="col-md-6">
                                            <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                                                <option class="filter" value="all" selected>All types</option>
                                                <option class="filter" value="jpaper">Jounal Papers</option>
                                                <option class="filter" value="cpaper">Conference Papers</option>
                                                <option class="filter" value="bookchapter">Book Chapters</option>
                                                <option class="filter" value="book">Books</option>
                                                <option class="filter" value="report">Reports</option>
                                                <option class="filter" value="tpaper">Technical Papers</option>
                                            </select>
                                        </div>

                                        <div class="col-md-3" id="sort">
                                            <span>Sort by year:</span>
                                            <div class="btn-group pull-right">

                                                <button type="button" data-sort="data-year" data-order="desc" class="sort btn btn-default"><i class="icon-sort-by-order"></i></button>
                                                <button type="button" data-sort="data-year" data-order="asc" class="sort btn btn-default"><i class="icon-sort-by-order-alt"></i></button>
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div> -->
            
            <div class="section color-2" id="pub-grid">
              <div class="section-container">
                <br/>
                <div class="row">
                  <div class="col-md-12">
                    <div class="pitems">

                      <!-- ###### TALISMAN ##########-->
                      <div class="item mix cpaper" data-year="2022">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/2112.00166" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">TALISMAN: Targeted Active Learning for Object Detection with Rare Classes and Slices using Submodular Mutual Information</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Saikat Ghosh, Sumit Shekhar, Yu Xiang, and Rishabh Iyer</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span> European Conference in Computer Vision, ECCV 2022.</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Deep neural networks based object detectors have shown great success in a variety of domains like autonomous vehicles, biomedical imaging, etc. It is known that their success depends on a large amount of data from the domain of interest. While deep models often perform well in terms of overall accuracy, they often struggle in performance on rare yet critical data slices. For example, data slices like "motorcycle at night" or "bicycle at night" are often rare but very critical slices for self-driving applications and false negatives on such rare slices could result in ill-fated failures and accidents. Active learning (AL) is a well-known paradigm to incrementally and adaptively build training datasets with a human in the loop. However, current AL based acquisition functions are not well-equipped to tackle real-world datasets with rare slices, since they are based on uncertainty scores or global descriptors of the image. We propose TALISMAN, a novel framework for Targeted Active Learning or object detectIon with rare slices using Submodular MutuAl iNformation. Our method uses the submodular mutual information functions instantiated using features of the region of interest (RoI) to efficiently target and acquire data points with rare slices. We evaluate our framework on the standard PASCAL VOC07+12 and BDD100K, a real-world self-driving dataset. We observe that TALISMAN outperforms other methods by in terms of average precision on rare slices, and in terms of mAP.</p>
                        </div>
                      </div>
                      
                      <!-- ###### PROBE DSN ##########-->
                      <!-- <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/2010.08593" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">PROBE: Deep Submodular Networks for Subset Selection</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, and Rishabh Iyer</div>
                          <div class="pubcite"><span class="label label-warning">Preprint</span> arXiv preprint arXiv:2010.08593.</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Deep Models are increasingly becoming prevalent in summarization problems (e.g. document, video and images) due to their ability to learn complex feature interactions and representations. However, they do not model characteristics such as diversity, representation, and coverage, which are also very important for summarization tasks. On the other hand, submodular functions naturally model these characteristics because of their diminishing returns property. Most approaches for modelling and learning submodular functions rely on very simple models, such as weighted mixtures of submodular functions. Unfortunately, these models only learn the relative importance of the different submodular functions (such as diversity, representation or importance), but cannot learn more complex feature representations, which are often required for state-of-the-art performance. We propose Deep Submodular Networks (DSN), an end-to-end learning framework that facilitates the learning of more complex features and richer functions, crafted for better modelling of all aspects of summarization. The DSN framework can be used to learn features appropriate for summarization from scratch. We demonstrate the utility of DSNs on both generic and query focused image-collection summarization, and show significant improvement over the state-of-the-art. In particular, we show that DSNs outperform simple mixture models using off the shelf features. Secondly, we also show that just using four submodular functions in a DSN with end-to-end learning performs comparably to the state-of-the-art mixture model with a hand-crafted set of 594 components and outperforms other methods for image collection summarization.</p>
                        </div>
                      </div> -->

                      <!-- ###### AUTO-DISCERN ##########-->
                      <!-- <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/2110.13606" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">AUTO-DISCERN: Autonomous Driving Using Common Sense Reasoning</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>,  Vinaya Khandelwal, Kinjal Basu, Huaduo Wang, Gopal Gupta</div>
                          <div class="pubcite"><span class="label label-warning">Preprint</span> arXiv preprint arXiv:2110.13606.</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Driving an automobile involves the tasks of observing surroundings, then making a driving decision based on these observations (steer, brake, coast, etc.). In autonomous driving, all these tasks have to be automated. Autonomous driving technology thus far has relied primarily on machine learning techniques. We argue that appropriate technology should be used for the appropriate task. That is, while machine learning technology is good for observing and automatically understanding the surroundings of an automobile, driving decisions are better automated via commonsense reasoning rather than machine learning. In this paper, we discuss (i) how commonsense reasoning can be automated using answer set programming (ASP) and the goal-directed s(CASP) ASP system, and (ii) develop the AUTO-DISCERN system using this technology for automating decision-making in driving. The goal of our research, described in this paper, is to develop an autonomous driving system that works by simulating the mind of a human driver. Since driving decisions are based on human-style reasoning, they are explainable, their ethics can be ensured, and they will always be correct, provided the system modeling and system inputs are correct.</p>
                        </div>
                      </div> -->

                      <!-- ###### PRISM ##########-->
                      <div class="item mix cpaper" data-year="2022">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/1809.08846" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">PRISM: A Rich Class of Parameterized Submodular Information Measures for Guided Subset Selection</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Vishal Kaushal, Ganesh Ramakrishnan, Jeff Bilmes, Rishabh Iyer</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>In the Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022.
                          </div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>With ever-increasing dataset sizes, subset selection techniques are becoming increasingly important for a plethora of tasks. It is often necessary to guide the subset selection to achieve certain desiderata, which includes focusing or targeting certain data points, while avoiding others. Examples of such problems include: i)targeted learning, where the goal is to find subsets with rare classes or rare attributes on which the model is under performing, and ii)guided summarization, where data (e.g.,image collection, text, document or video) is summarized for quicker human consumption with specific additional user in-tent. Motivated by such applications, we present PRISM, a rich class of PaRameterIzed Submodular information Measures. Through novel functions and their parameterizations, PRISM offers a variety of modeling capabilities that enable a trade-off between desired qualities of a subset like diversity or representation and similarity/dissimilarity with a set of data points. We demonstrate how PRISM can be applied to the two real-world problems mentioned above, which require guided subset selection. In doing so, we show that PRISM interestingly generalizes some past work, therein reinforcing its broad utility. Through extensive experiments on diverse datasets, we demonstrate the superiority of PRISM over the state-of-the-art in targeted learning and in guided image-collection summarization.</p>
                        </div>
                      </div>

                      <!-- ###### Deep Template Matching ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <!-- <a href="https://arxiv.org/abs/1809.08846" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a> -->

                          </div>

                          <h4 class="pubtitle">Object Level Targeted Selection using Deep Template Matching</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Donna Roy, Michele Fenzi, Elmar Haussman, Jose M. Alvarez, and Christoph Angerer.</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span> Intelligient Vehicles Symposium, IV 2022</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Retrieving images with objects that are semantically similar to objects of interest (OOI) in a query image has many practical use cases. A few examples include fixing failures like false negatives/positives of a learned model or mitigating class imbalance in a dataset. The targeted selection task requires finding the relevant data from a large-scale pool of unlabeled data. Manual mining at this scale is infeasible. Further, the OOI are often small and occupy less than 1\% of image area, are occluded, and co-exist with many semantically different objects in cluttered scenes. Existing semantic image retrieval methods often focus on mining for larger sized geographical landmarks, and/or require extra labeled data, such as images/image-pairs with similar objects, for mining images with generic objects. We propose a fast and robust template matching algorithm in the DNN feature space, that retrieves semantically similar images at the object-level from a large unlabeled pool of data. We project the region(s) around the OOI in the query image to the DNN feature space for use as the template. This enables our method to focus on the semantics of the OOI without requiring extra labeled data. In the context of  autonomous driving, we evaluate our system for targeted selection by using failure cases of object detectors as OOI. We demonstrate its efficacy on a large unlabeled dataset with 2.2M images and show high recall in mining for images with small-sized OOI. We compare our method against a well-known semantic image retrieval method, which also does not require extra labeled data. Lastly, we show that our method is flexible and retrieves images with one or more semantically different co-occurring OOI seamlessly.</p>
                        </div>
                      </div>

                      <!-- ###### SIMILAR ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="icon-expand-alt"></i>
                          </a>
                            <a href="https://arxiv.org/abs/2107.00717" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                              <i class="ai ai-arxiv"></i>
                                                          </a>
                          </div>
                          <h4 class="pubtitle">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Nathan Beck, Krishnateja Killamsetty, Rishabh Iyer</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>To Appear at the 35th Conference on Neural Information Processing Systems, NeurIPS 2021.
                          </div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Active learning has proven to be useful for minimizing labeling costs by selecting the most informative samples. However, existing active learning methods do not work well in realistic scenarios such as imbalance or rare classes, out-of-distribution data in the unlabeled set, and redundancy. In this work, we propose SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions. We argue that SIMILAR not only works in standard active learning, but also easily extends to the realistic settings considered above and acts as a one-stop solution for active learning that is scalable to large real-world datasets. Empirically, we show that SIMILAR significantly outperforms existing active learning algorithms by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case of out-of-distribution data on several image classification tasks like CIFAR-10, MNIST, and ImageNet.</p>
                        </div>
                      </div>

                      <!-- ###### Robotic lime picking ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="icon-expand-alt"></i>
                          </a>
                            <a href="https://arxiv.org/abs/2107.00717" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                              <i class="ai ai-arxiv"></i>
                                                          </a>
                          </div>
                          <h4 class="pubtitle">Robotic Lime Picking by Considering Leaves as Permeable Obstacles</h4>
                          <div class="pubauthor">Heramb Nemlekar, Ziang Liu, <strong>Suraj Kothawade</strong>,  Sherdil Niyaz, Barath Raghavan, Stefanos Nikolaidis</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span> International Conference on Intelligent Robots and Systems (IROS 2021).
                          </div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>The problem of robotic lime picking is challenging; lime plants have dense foliage which makes it difficult for a robotic arm to grasp a lime without coming in contact with leaves. Existing approaches either do not consider leaves, or treat them as obstacles and completely avoid them, often resulting in undesirable or infeasible plans. We focus on reaching a lime in the presence of dense foliage by considering the leaves of a plant as 'permeable obstacles' with a collision cost. We then adapt the rapidly exploring random tree star (RRT*) algorithm for the problem of fruit harvesting by incorporating the cost of collision with leaves into the path cost. To reduce the time required for finding low-cost paths to goal, we bias the growth of the tree using an artificial potential field (APF). We compare our proposed method with prior work in a 2-D environment and a 6-DOF robot simulation. Our experiments and a real-world demonstration on a robotic lime picking task demonstrate the applicability of our approach.</p>
                        </div>
                      </div>

                      <!-- ###### Learning from less data ##########-->
                      <div class="item mix cpaper" data-year="2019">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="icon-expand-alt"></i>
                          </a>
                            <a href="https://arxiv.org/abs/1901.01151" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                              <i class="ai ai-arxiv"></i>
                                                          </a>
                          </div>
                          <h4 class="pubtitle">Learning From Less Data: A Unified Data Subset Selection and Active Learning Framework for Computer Vision</h4>
                          <div class="pubauthor">Vishal Kaushal, Rishabh Iyer, <strong>Suraj Kothawade</strong>, et al.</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>IEEE Winter Conference on Applications of Computer Vision (WACV) 2019</div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Supervised machine learning based state-of-the-art computer vision techniques are in general data hungry. Their data curation poses the challenges of expensive human labeling, inadequate computing resources and larger experiment turn around times. Training data subset selection and active learning techniques have been proposed as possible solutions to these challenges. A special class of subset selection functions naturally model notions of diversity, coverage and representation and can be used to eliminate redundancy thus lending themselves well for training data subset selection. They can also help improve the efficiency of active learning in further reducing human labeling efforts by selecting a subset of the examples obtained using the conventional uncertainty sampling based techniques. In this work, we empirically demonstrate the effectiveness of two diversity models, namely the Facility-Location and Dispersion models for training-data subset selection and reducing labeling effort. We demonstrate this across the board for a variety of computer vision tasks including Gender Recognition, Face Recognition, Scene Recognition, Object Detection and Object Recognition. Our results show that diversity based subset selection done in the right way can increase the accuracy by upto 5 - 10% over existing baselines, particularly in settings in which less training data is available. This allows the training of complex machine learning models like Convolutional Neural Networks with much less training data and labeling costs while incurring minimal performance loss.</p>
                        </div>
                      </div>

                      <!-- ###### Domain Specific Video Summarization ##########-->
                      <div class="item mix cpaper" data-year="2019">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/1809.08854" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">A Framework towards Domain Specific Video Summarization</h4>
                          <div class="pubauthor">Vishal Kaushal, Sandeep Subramanian, <strong>Suraj Kothawade</strong>, Rishabh Iyer, Ganesh Ramakrishnan</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>IEEE Winter Conference on Applications of Computer Vision (WACV) 2019</div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>In the light of exponentially increasing video content, video summarization has attracted a lot of attention recently due to its ability to optimize time and storage. Characteristics of a good summary of a video depend on the particular domain under question. We propose a novel framework for domain specific video summarization. Given a video of a particular domain, our system can produce a summary based on what is important for that domain in addition to possessing other desired characteristics like representativeness, coverage, diversity etc. as suitable to that domain. Past related work has focused either on using supervised approaches for ranking the snippets to produce summary or on using unsupervised approaches of generating the summary as a subset of snippets with the above characteristics. We look at the joint problem of learning domain specific importance of segments as well as the desired summary characteristic for that domain. Our studies show that the more efficient way of incorporating domain specific relevances into a summary is by obtaining ratings of shots as opposed to binary inclusion/exclusion information. We also argue that ratings can be seen as unified representation of all possible ground truth summaries of a video, taking us one step closer in dealing with challenges associated with multiple ground truth summaries of a video. We also propose a novel evaluation measure which is more naturally suited in assessing the quality of video summary for the task at hand than F1 like measures. It leverages the ratings information and is richer in appropriately modeling desirable and undesirable characteristics of a summary. Lastly, we release a gold standard dataset for furthering research in domain specific video summarization, which to our knowledge is the first dataset with long videos across several domains with rating annotations.</p>
                        </div>
                      </div>
                      
                      <!-- ###### Demystifying Multi-Faceted Video Summarization: Tradeoff Between Diversity, Representation, Coverage and Importance ##########-->
                      <div class="item mix cpaper" data-year="2019">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="icon-expand-alt"></i>
                            </a>      
                            <a href=https://arxiv.org/abs/1901.01153" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                              <i class="ai ai-arxiv"></i>
                            </a>                        
                          </div>
                          <h4 class="pubtitle">Demystifying Multi-Faceted Video Summarization: Tradeoff Between Diversity, Representation, Coverage and Importance</h4>
                          <div class="pubauthor">Vishal Kaushal, Rishabh Iyer, <strong>Suraj Kothawade</strong>, et al.</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>IEEE Winter Conference on Applications of Computer Vision (WACV) 2019</div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>This paper addresses automatic summarization of videos in a unified manner. In particular, we propose a framework for multi-faceted summarization for extractive, query base and entity summarization (summarization at the level of entities like objects, scenes, humans and faces in the video). We investigate several summarization models which capture notions of diversity, coverage, representation and importance, and argue the utility of these different models depending on the application. While most of the prior work on submodular summarization approaches has focused oncombining several models and learning weighted mixtures, we focus on the explainability of different models and featurizations, and how they apply to different domains. We also provide implementation details on summarization systems and the different modalities involved. We hope that the study from this paper will give insights into practitioners to appropriately choose the right summarization models for the problems at hand.</p>
                        </div>
                      </div>

                      <!-- ###### Learning Collaborative Action Plans from YouTube Videos ##########-->
                      <div class="item mix cpaper" data-year="2019">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="icon-expand-alt"></i>
                            </a>
                            <a href="https://www.hejiazhang.me/papers/isrr2019.pdf" class="tooltips" title="External Link" target="_blank" rel="noopener noreferrer">
                              <i class="icon-external-link"></i>
                            </a>
                          </div>
                          <h4 class="pubtitle">Learning Collaborative Action Plans from YouTube Videos</h4>
                          <div class="pubauthor">Hejia Zhang, Po-Jen Lai, Sayan Paul, <strong>Suraj Kothawade</strong> and Stefanos Nikolaidis</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>International Symposium on Robotics Research (ISRR) 2019</div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Videos from the World Wide Web provide a rich source of                       information that robots could use to acquire knowledge about manipulation tasks. Previous work has focused on generating action sequences
                            from unconstrained videos for a single robot performing manipulation
                            tasks by itself. However, robots operating in the same physical space
                            with people need to not only perform actions autonomously, but also coordinate seamlessly with their human counterparts. This often requires
                            representing and executing collaborative manipulation actions, such as
                            handing over a tool or holding an object for the other agent. We present
                            a system for knowledge acquisition of collaborative manipulation action
                            plans that outputs commands to the robot in the form of visual sentence. We show the performance of the system in 12 unlabeled action
                            clips taken from collaborative cooking videos on YouTube. We view this
                            as the first step towards extracting collaborative manipulation action
                            sequences from unconstrained, unlabeled online videos</p>
                        </div>
                      </div>
                      

                      <!-- ###### Targeted AL for MEDICAL DATA ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <!-- <a href="https://arxiv.org/abs/1809.08846" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a> -->

                          </div>

                          <h4 class="pubtitle">Targeted Active Learning using Submodular Mutual Information for Imbalanced Medical Image Classification</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Lakshman Tamil, and Rishabh Iyer.</div>
                          <div class="pubcite"><span class="label label-primary">Workshop Paper</span> Medical Imaging Meets NeurIPSWorkshop at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Training deep learning models on medical datasets that perform well for all classes is a challenging task. It is often the case that a suboptimal performance is obtained on some classes due to the natural class imbalance issue that comes with medical data. An effective way to tackle this problem is by using targeted active learning, where we iteratively add data points to the training data that belong to the rare classes. However, existing active learning methods are ineffective in targeting rare classes in medical datasets. In this work, we propose TALISMAN, a framework for targeted active learning that uses submodular mutual information functions as acquisition functions. We show that TALISMAN outperforms the state-of-the-art active learning methods by ~10%-12% on the rare classes accuracy and ~4%-6% on overall accuracy for Path-MNIST and Pneumonia-MNIST image classification datasets.</p>
                        </div>
                      </div>


                      <!-- ###### Submodular Mutual Information for Targeted Data Subset Selection ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/pdf/2105.00043.pdf" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">Submodular Mutual Information for
                            Targeted Data Subset Selection</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Vishal Kaushal, Ganesh Ramakrishnan, Jeff Bilmes, and Rishabh Iyer.</div>
                          <div class="pubcite"><span class="label label-primary">Workshop Paper</span> In ICLR 2021 Workshop: From Shallow to Deep: Overcoming Limited and Adverse Data</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>With the rapid growth of data, it is becoming increasingly difficult to train or improve deep learning models with the right subset of data. We show that this problem can be effectively solved at an additional labeling cost by targeted data subset selection(TSS) where a subset of unlabeled data points similar to an auxiliary set are added to the training data. We do so by using a rich class of Submodular Mutual Information (SMI) functions and demonstrate its effectiveness for image classification on CIFAR-10 and MNIST datasets. Lastly, we compare the performance of SMI functions for TSS with other state-of-the-art methods for closely related problems like active learning. Using SMI functions, we observe ~20-30% gain over the model's performance before re-training with added targeted subset; ~12% more than other methods.</p>
                        </div>
                      </div>


                      <!-- ###### SIMILAR ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="icon-expand-alt"></i>
                          </a>
                            <a href="https://arxiv.org/abs/2107.00717" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                              <i class="ai ai-arxiv"></i>
                                                          </a>
                          </div>
                          <h4 class="pubtitle">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Nathan Beck, Krishnateja Killamsetty, Rishabh Iyer</div>
                          <div class="pubcite"><span class="label label-primary">Workshop Paper</span> ICML 2021 Workshop: Subset Selection in Machine Learning.
                          </div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Active learning has proven to be useful for minimizing labeling costs by selecting the most informative samples. However, existing active learning methods do not work well in realistic scenarios such as imbalance or rare classes, out-of-distribution data in the unlabeled set, and redundancy. In this work, we propose SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions. We argue that SIMILAR not only works in standard active learning, but also easily extends to the realistic settings considered above and acts as a one-stop solution for active learning that is scalable to large real-world datasets. Empirically, we show that SIMILAR significantly outperforms existing active learning algorithms by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case of out-of-distribution data on several image classification tasks like CIFAR-10, MNIST, and ImageNet.</p>
                        </div>
                      </div>

                      <!-- ###### AUTO-DISCERN ##########-->
                      <div class="item mix cpaper" data-year="2021">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/2110.13606" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">AUTO-DISCERN: Autonomous Driving Using Common Sense Reasoning</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>,  Vinaya Khandelwal, Kinjal Basu, Huaduo Wang, Gopal Gupta</div>
                          <div class="pubcite"><span class="label label-primary">Workshop Paper</span> ICLP 2021 Workshop on Goal-directed Execution of Answer Set Programs</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Driving an automobile involves the tasks of observing surroundings, then making a driving decision based on these observations (steer, brake, coast, etc.). In autonomous driving, all these tasks have to be automated. Autonomous driving technology thus far has relied primarily on machine learning techniques. We argue that appropriate technology should be used for the appropriate task. That is, while machine learning technology is good for observing and automatically understanding the surroundings of an automobile, driving decisions are better automated via commonsense reasoning rather than machine learning. In this paper, we discuss (i) how commonsense reasoning can be automated using answer set programming (ASP) and the goal-directed s(CASP) ASP system, and (ii) develop the AUTO-DISCERN system using this technology for automating decision-making in driving. The goal of our research, described in this paper, is to develop an autonomous driving system that works by simulating the mind of a human driver. Since driving decisions are based on human-style reasoning, they are explainable, their ethics can be ensured, and they will always be correct, provided the system modeling and system inputs are correct.</p>
                        </div>
                      </div>


                      <!-- ###### VISIOCITY ##########-->
                      <div class="item mix cpaper" data-year="2020">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/2007.14560" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">Realistic Video Summarization through VISIOCITY:
                            A New Benchmark and Evaluation Framework.</h4>
                          <div class="pubauthor"> Vishal Kaushal, <strong>Suraj Kothawade</strong>, Rishabh Iyer and Ganesh Ramakrishnan</div>
                          <div class="pubcite"><span class="label label-primary">Workshop Paper</span> In Proceedings of the ACMMM 2nd International Workshop on AI for
                            Smart TV Content Production, Access and Delivery, pp. 37-44, 2020.</div>

                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>Automatic video summarization is still an unsolved problem due to several challenges. We take steps towards making automatic video summarization more realistic by addressing them. Firstly, the currently available datasets either have very short videos or have few long videos of only a particular type. We introduce a new benchmarking dataset VISIOCITY which comprises of longer videos across six different categories with dense concept annotations capable of supporting different flavors of video summarization and can be used for other vision problems. Secondly, for long videos, human reference summaries are difficult to obtain. We present a novel recipe based on pareto optimality to automatically generate multiple reference summaries from indirect ground truth present in VISIOCITY. We show that these summaries are at par with human summaries. Thirdly, we demonstrate that in the presence of multiple ground truth summaries (due to the highly subjective nature of the task), learning from a single combined ground truth summary using a single loss function is not a good idea. We propose a simple recipe VISIOCITY-SUM to enhance an existing model using a combination of losses and demonstrate that it beats the current state of the art techniques when tested on VISIOCITY. We also show that a single measure to evaluate a summary, as is the current typical practice, falls short. We propose a framework for better quantitative assessment of summary quality which is closer to human judgment than a single measure, say F1. We report the performance of a few representative techniques of video summarization on VISIOCITY assessed using various measures and bring out the limitation of the techniques and/or the assessment mechanism in modeling human judgment and demonstrate the effectiveness of our evaluation framework in doing so.</p>
                        </div>
                      </div>

                      <!-- ###### VIS - DSS ##########-->
                      <!-- <div class="item mix cpaper" data-year="2018">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/1809.08846" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">Vis-DSS: An Open-Source toolkit for Visual Data Selection and Summarization</h4>
                          <div class="pubauthor">Rishabh Iyer, Pratik Dubal, Kunal Dargan, <strong>Suraj Kothawade</strong>, Rohan Mahadev and Vishal Kaushal</div>
                          <div class="pubcite"><span class="label label-warning">Preprint</span> arXiv preprint arXiv:1809.08846</div>

                        </div>
                        <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Although a substantial amount of research has examined the constructs of warmth and competence, far less has examined how these constructs develop and what benefits may accrue when warmth and competence are cultivated. Yet there are positive consequences, both emotional and behavioral, that are likely to occur when brands hold perceptions of both. In this paper, we shed light on when and how warmth and competence are jointly promoted in brands, and why these reputations matter.</p>
                        </div>
                      </div> -->

                      <!-- ###### CBIR on Satellite Images ##########-->
                      <!-- <div class="item mix cpaper" data-year="2018">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                            <a href="https://arxiv.org/abs/1809.10190" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                                <i class="ai ai-arxiv"></i>
                                                            </a>

                          </div>

                          <h4 class="pubtitle">Content Based Image Retrieval from AWiFS Images Repository of IRS Resourcesat-2 Satellite Based on Water Bodies and Burnt Areas</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Kunjan Mhaske, Sahil Sharma, Furkhan Shaikh</div>
                          <div class="pubcite"><span class="label label-warning">Preprint</span> arXiv preprint arXiv:1809.10190</div>

                        </div>
                      </div> -->

                      <!-- ###### Deployment of Customized Deep Learning based Video Analytics On Surveillance Cameras ##########-->
                      <!-- <div class="item mix cpaper" data-year="2018">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="https://arxiv.org/abs/1805.10604" class="tooltips" title="arXiv Page" target="_blank" rel="noopener noreferrer">
                                                              <i class="ai ai-arxiv"></i>
                                                          </a>
                          </div>
                          <h4 class="pubtitle">Deployment of Customized Deep Learning based Video Analytics On Surveillance Cameras</h4>
                          <div class="pubauthor">Pratik Dubal, Rohan Mahadev, <strong>Suraj Kothawade</strong>, Kunal Dargan and Rishabh Iyer</div>
                          <div class="pubcite">
                            <span class="label label-warning">Preprint</span> arXiv preprint arXiv:1805.10604
                          </div>
                        </div>
                      </div> -->


                      <!-- <div class="item mix cpaper" data-year="2015">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="https://ieeexplore.ieee.org/document/8524167" class="tooltips" title="External Link" target="_blank" rel="noopener noreferrer">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                          </div>

                          <h4 class="pubtitle">Application of Deep Convolutional Neural Network to Prevent ATM Fraud by Facial Disguise Identification</h4>
                          <div class="pubauthor">Sumit Tamgale, <strong>Suraj Kothawade</strong></div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>2017 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)</div>
                        </div>
                      </div>

                      <div class="item mix cpaper" data-year="2015">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7853281" class="tooltips" title="External Link" target="_blank" rel="noopener noreferrer">
                                                              <i class="icon-external-link"></i>
                                                          </a>
                          </div>

                          <h4 class="pubtitle">Efficient Water Management for Greenland using Soil Moisture Sensor</h4>
                          <div class="pubauthor"><strong>Suraj Kothawade</strong>, Furkhan Shaikh, Kunjan Mhaske</div>
                          <div class="pubcite"><span class="label label-primary">Conference Paper</span>2016 IEEE 1st International Conference on Power Electronics, Intelligent Control and Energy Systems (ICPEICES)</div>
                        </div>
                      </div> -->

                    </div>
                  </div>
                </div>

              </div>
            </div>

          </div>
        </div>
      </div>

      <!-- <div id="gallery" class="page">
                    <div class="pagecontents">

                        <div class="section color-3" id="gallery-header">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-3">
                                        <h2>Gallery</h2>
                                    </div>
                                    <div class="col-md-9">
                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="section color-3" id="gallery-large">
                            <div class="section-container">

                                <ul id="grid" class="grid">
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/06.jpg">
                                            <a href="img/gallery/06.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/02.jpg">
                                            <a href="img/gallery/02.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/03.jpg">
                                            <a href="img/gallery/03.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/04.jpg">
                                            <a href="img/gallery/04.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/05.jpg">
                                            <a href="img/gallery/05.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/01.jpg">
                                            <a href="img/gallery/01.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/07.jpg">
                                            <a href="img/gallery/07.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/08.jpg">
                                            <a href="img/gallery/08.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/09.jpg">
                                            <a href="img/gallery/09.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/10.jpg">
                                            <a href="img/gallery/10.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/11.jpg">
                                            <a href="img/gallery/11.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/12.jpg">
                                            <a href="img/gallery/12.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/07.jpg">
                                            <a href="img/gallery/07.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/02.jpg">
                                            <a href="img/gallery/02.jpg" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>


                                </ul>

                            </div>
                        </div>
                    </div>

                </div> -->
      <div id="contact" class="page stellar">
        <div class="pageheader">
          <div class="headercontent">
            <div class="section-container">

              <h2 class="title">Contact Details</h2>

              <div class="row">
                <div class="col-md-7">
                  <p id="biodesc"> Please feel free to reach out to me if you have any questions regarding my work or if you just want to talk about interesting stuff in Computer Vision and Machine Learning.</p>
                </div>
                <div class="col-md-5">
                  <ul class="list-unstyled">
                    <!-- <li>
                                                <strong><i class="icon-phone"></i>&nbsp;&nbsp;</strong>
                                                <span>office: 808-808 88 88</span>
                                            </li> -->
                    <li>
                      <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
                      <span>suraj.kothawade AT utdallas DOT edu</span>
                    </li>
                    <!-- <li>
                                                <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
                                                <span>suraj DOT kothawade AT utdallas DOT edu</span>
                                            </li> -->
                    <li>
                      <strong><i class="icon-github-sign"></i>&nbsp;&nbsp;</strong>
                      <span><a href="https://github.com/surajkothawade" target="_blank" rel="noopener noreferrer">github.com/surajkothawade</a></span>
                    </li>
                    <li>
                      <strong><i class="icon-linkedin-sign"></i>&nbsp;&nbsp;</strong>
                      <span><a href="https://www.linkedin.com/in/suraj-kothawade-6835b5a9/" target="_blank" rel="noopener noreferrer">linkedin.com/in/suraj-kothawade-6835b5a9/</a></span>
                    </li>
                  </ul>

                </div>
              </div>
            </div>
          </div>
        </div>
        <!-- <div class="pagecontents">
                        <div class="section contact-office" data-stellar-background-ratio="0.1">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-8">
                                        <h2 class="title">At My Office</h2>
                                        <p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                        <p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                                    </div>
                                    <div class="col-md-4 text-center hidden-xs hidden-sm">
                                        <i class="icon-coffee icon-huge"></i>
                                    </div>

                                </div>
                            </div>
                        </div>
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-4 text-center hidden-xs hidden-sm">
                                        <i class="icon-stethoscope icon-huge"></i>
                                    </div>
                                    <div class="col-md-8">
                                        <h2 class="title">At My Work</h2>
                                        <p>You can find me at my Work located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                        <p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="section contact-lab" data-stellar-background-ratio="0.1">
                            <div class="section-container">
                                <div class="row">

                                    <div class="col-md-8">
                                        <h2 class="title">At My Lab</h2>
                                        <p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                        <p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
                                    </div>
                                    <div class="col-md-4 text-center hidden-xs hidden-sm">
                                        <i class="icon-superscript icon-huge"></i>
                                    </div>

                                </div>
                            </div>
                        </div>
                    </div> -->

      </div>

      <div id="overlay"></div>

    </div>
  </div>
</body>

</html>
